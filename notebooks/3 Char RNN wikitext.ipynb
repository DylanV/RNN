{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load wikitext-2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), '..', 'data', 'wikitext-2-raw')\n",
    "train_path = os.path.join(data_dir, 'wiki.test.raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(train_path, encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n = Robert Boulter = \\n \\n Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm ; '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^abcdefghijklmnopqrstuvwxyz£¥©°½ÁÆÉ×ßàáãäåæçèéêëíîñóôöúüćčěīłŌōŠūžǐǔǜəɛɪʊˈː̍͘ΠΩέαβδειλμνοπςστυωόПвдикнאבילרשתاتدسكلوڠगनरलषुेो्ảẩ‑–—’“”†‡…⁄₩₱→−♯のアイクグジダッドナブラル中为伊傳八利前勢史型士大学宝开律成戦春智望杜東民王甫田甲秘聖艦處衛解詩贈邵都鉄集魯'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(sorted(set(text)))\n",
    "# for padding\n",
    "chars.insert(0, \"\\0\")\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 260\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "print(f'Total characters: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps\n",
    "char_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_char = {idx: char for idx, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_text = [char_idx[char] for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 2, 31, 2, 52, 78, 65, 68, 81, 83, 2, 36, 78, 84, 75, 83, 68, 81, 2, 31, 2, 1, 2, 1, 2, 52, 78, 65, 68, 81, 83, 2, 36, 78, 84, 75, 83, 68, 81, 2, 72, 82, 2, 64, 77, 2, 39, 77, 70, 75, 72, 82, 71, 2, 69, 72, 75, 76, 2, 14, 2, 83, 68, 75, 68, 85, 72, 82, 72, 78, 77, 2, 64, 77, 67, 2, 83, 71, 68, 64, 83, 81, 68, 2, 64, 66, 83, 78, 81, 2, 16, 2, 42, 68, 2, 71, 64, 67, 2]\n",
      "[' ', '\\n', ' ', '=', ' ', 'R', 'o', 'b', 'e', 'r', 't', ' ', 'B', 'o', 'u', 'l', 't', 'e', 'r', ' ', '=', ' ', '\\n', ' ', '\\n', ' ', 'R', 'o', 'b', 'e', 'r', 't', ' ', 'B', 'o', 'u', 'l', 't', 'e', 'r', ' ', 'i', 's', ' ', 'a', 'n', ' ', 'E', 'n', 'g', 'l', 'i', 's', 'h', ' ', 'f', 'i', 'l', 'm', ' ', ',', ' ', 't', 'e', 'l', 'e', 'v', 'i', 's', 'i', 'o', 'n', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', 'a', 't', 'r', 'e', ' ', 'a', 'c', 't', 'o', 'r', ' ', '.', ' ', 'H', 'e', ' ', 'h', 'a', 'd', ' ']\n"
     ]
    }
   ],
   "source": [
    "print(idx_text[:100])\n",
    "print([idx_char[idx] for idx in idx_text[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, text):\n",
    "        \n",
    "        chars = list(sorted(set(text)))\n",
    "        chars.insert(0, \"\\0\")\n",
    "        \n",
    "        vocab_size = len(chars)\n",
    "        # Maps\n",
    "        char_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "        idx_char = {idx: char for idx, char in enumerate(chars)}\n",
    "        \n",
    "        idx_text = [char_idx[char] for char in text]\n",
    "        \n",
    "        cs=3\n",
    "        c1_dat = [idx_text[i]   for i in range(0, len(idx_text)-cs, cs)]\n",
    "        c2_dat = [idx_text[i+1] for i in range(0, len(idx_text)-cs, cs)]\n",
    "        c3_dat = [idx_text[i+2] for i in range(0, len(idx_text)-cs, cs)]\n",
    "        c4_dat = [idx_text[i+3] for i in range(0, len(idx_text)-cs, cs)]\n",
    "        \n",
    "        x = np.vstack((np.stack(c1_dat), np.stack(c2_dat), np.stack(c3_dat))).T\n",
    "        y = np.stack(c4_dat)\n",
    "        \n",
    "        self.x = torch.from_numpy(x)\n",
    "        self.y = torch.from_numpy(y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(text)\n",
    "data_generator = data.DataLoader(dataset, batch_size=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "n_fac = 42\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "\n",
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "\n",
    "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "\n",
    "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.functional' has no attribute 'nll_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-1657549d8789>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChar3Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.functional' has no attribute 'nll_loss'"
     ]
    }
   ],
   "source": [
    "model = Char3Model(vocab_size, n_fac).cuda()\n",
    "loss_fn = F.nll_loss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.functional' has no attribute 'nll_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-082b0efda5a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChar3Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.functional' has no attribute 'nll_loss'"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "for epoch in range(max_epochs):\n",
    "    for x, y in data_generator:\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        print(t, loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
